{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": /physical_device:CPU:0\n",
      ": /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(\": {}\".format(device.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Found 42559 files belonging to 65 classes.\n",
      "Using 38304 files for training.\n",
      "Found 42559 files belonging to 65 classes.\n",
      "Using 4255 files for validation.\n",
      "Found 10640 files belonging to 1 classes.\n",
      "Class names: ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warnings and logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (224, 224)  # Directly using ResNet50 input size\n",
    "BATCH_SIZE = 64\n",
    "TRAINING_DATA_PATH = \"Final_Arabic_Alpha_dataset/train\"\n",
    "TEST_DATA_PATH = \"Final_Arabic_Alpha_dataset/test\"\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAINING_DATA_PATH,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAINING_DATA_PATH,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DATA_PATH,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    label_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating preprocessing pipeline...\n",
      "Building model...\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and preprocessing\n",
    "print(\"Creating preprocessing pipeline...\")\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#     tf.keras.layers.RandomRotation(0.2, seed=SEED),\n",
    "#     tf.keras.layers.RandomZoom(0.1, seed=SEED),\n",
    "# ])\n",
    "\n",
    "resnet_preprocess = tf.keras.applications.resnet50.preprocess_input\n",
    "\n",
    "# Build model\n",
    "print(\"Building model...\")\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(*IMAGE_SIZE, 3)\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(*IMAGE_SIZE, 3))\n",
    "# x = data_augmentation(inputs)\n",
    "x = inputs\n",
    "x = resnet_preprocess(x)\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Freeze base model initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/5\n",
      "599/599 [==============================] - 162s 206ms/step - loss: 1.3761 - accuracy: 0.6104 - val_loss: 0.8457 - val_accuracy: 0.7358 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "599/599 [==============================] - 116s 192ms/step - loss: 0.6356 - accuracy: 0.8026 - val_loss: 0.6940 - val_accuracy: 0.7793 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "599/599 [==============================] - 115s 192ms/step - loss: 0.4772 - accuracy: 0.8486 - val_loss: 0.5988 - val_accuracy: 0.8094 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "599/599 [==============================] - 116s 193ms/step - loss: 0.3865 - accuracy: 0.8771 - val_loss: 0.5453 - val_accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "599/599 [==============================] - 116s 194ms/step - loss: 0.3331 - accuracy: 0.8928 - val_loss: 0.5200 - val_accuracy: 0.8364 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=1e-05>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Unfreeze some layers of the base model\n",
    "# fine_tune_at = 150  # Unfreeze from this layer onwards\n",
    "\n",
    "# base_model.trainable = True\n",
    "# for layer in base_model.layers[:fine_tune_at]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "model.optimizer.learning_rate.assign(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599/599 [==============================] - 116s 193ms/step - loss: 0.2244 - accuracy: 0.9332 - val_loss: 0.4321 - val_accuracy: 0.8639 - lr: 1.0000e-05\n",
      "Epoch 6/15\n",
      "599/599 [==============================] - 138s 231ms/step - loss: 0.2023 - accuracy: 0.9420 - val_loss: 0.4226 - val_accuracy: 0.8656 - lr: 1.0000e-05\n",
      "Epoch 7/15\n",
      "599/599 [==============================] - 159s 265ms/step - loss: 0.1967 - accuracy: 0.9439 - val_loss: 0.4178 - val_accuracy: 0.8672 - lr: 1.0000e-05\n",
      "Epoch 8/15\n",
      "599/599 [==============================] - 156s 259ms/step - loss: 0.1929 - accuracy: 0.9456 - val_loss: 0.4145 - val_accuracy: 0.8682 - lr: 1.0000e-05\n",
      "Epoch 9/15\n",
      "599/599 [==============================] - 147s 244ms/step - loss: 0.1899 - accuracy: 0.9466 - val_loss: 0.4119 - val_accuracy: 0.8684 - lr: 1.0000e-05\n",
      "Epoch 10/15\n",
      "599/599 [==============================] - 138s 230ms/step - loss: 0.1874 - accuracy: 0.9476 - val_loss: 0.4099 - val_accuracy: 0.8686 - lr: 1.0000e-05\n",
      "Epoch 11/15\n",
      "599/599 [==============================] - 124s 207ms/step - loss: 0.1853 - accuracy: 0.9490 - val_loss: 0.4082 - val_accuracy: 0.8696 - lr: 1.0000e-05\n",
      "Epoch 12/15\n",
      "599/599 [==============================] - 126s 209ms/step - loss: 0.1835 - accuracy: 0.9498 - val_loss: 0.4068 - val_accuracy: 0.8698 - lr: 1.0000e-05\n",
      "Epoch 13/15\n",
      "599/599 [==============================] - 121s 202ms/step - loss: 0.1818 - accuracy: 0.9502 - val_loss: 0.4057 - val_accuracy: 0.8710 - lr: 1.0000e-05\n",
      "Epoch 14/15\n",
      "599/599 [==============================] - 130s 217ms/step - loss: 0.1803 - accuracy: 0.9512 - val_loss: 0.4047 - val_accuracy: 0.8705 - lr: 1.0000e-05\n",
      "Epoch 15/15\n",
      "599/599 [==============================] - 128s 212ms/step - loss: 0.1789 - accuracy: 0.9515 - val_loss: 0.4037 - val_accuracy: 0.8717 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model again with fine-tuning\n",
    "fine_tune_epochs = 10  # Fine-tune for 10 more epochs\n",
    "total_epochs = EPOCHS + fine_tune_epochs  # Add to previous epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],  # Resume from where we left off\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model(\"arabic_letter_classifier_95_87\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599/599 [==============================] - 129s 192ms/step - loss: 0.1767 - accuracy: 0.9521\n",
      "67/67 [==============================] - 13s 186ms/step - loss: 0.4037 - accuracy: 0.8714\n",
      "Training loss: 0.1766589730978012, Training Accuracy: 0.9521459937095642\n",
      "Val loss: 0.40367570519447327, Val Accuracy: 0.87144535779953\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(train_ds)\n",
    "val_loss, val_accuracy = loaded_model.evaluate(val_ds)\n",
    "\n",
    "print(f\"Training loss: {loss}, Training Accuracy: {accuracy}\")\n",
    "print(f\"Val loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 19,994,177\n",
      "Non-trainable params: 4,134,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = loaded_model.get_layer(\"resnet50\")\n",
    "\n",
    "# Unfreeze some layers of the base model\n",
    "fine_tune_at = 100  # Unfreeze from this layer onwards\n",
    "\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "loaded_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "599/599 [==============================] - 193s 315ms/step - loss: 1.9411 - accuracy: 0.5785 - val_loss: 1.1386 - val_accuracy: 0.7001 - lr: 1.0000e-06\n",
      "Epoch 2/5\n",
      "599/599 [==============================] - 189s 315ms/step - loss: 0.7661 - accuracy: 0.7711 - val_loss: 0.8267 - val_accuracy: 0.7702 - lr: 1.0000e-06\n",
      "Epoch 3/5\n",
      "599/599 [==============================] - 189s 315ms/step - loss: 0.5357 - accuracy: 0.8318 - val_loss: 0.6937 - val_accuracy: 0.8005 - lr: 1.0000e-06\n",
      "Epoch 4/5\n",
      "599/599 [==============================] - 195s 325ms/step - loss: 0.4190 - accuracy: 0.8661 - val_loss: 0.6149 - val_accuracy: 0.8183 - lr: 1.0000e-06\n",
      "Epoch 5/5\n",
      "599/599 [==============================] - 193s 322ms/step - loss: 0.3364 - accuracy: 0.8897 - val_loss: 0.5614 - val_accuracy: 0.8310 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# Train the model again with fine-tuning\n",
    "fine_tune_epochs = 5  # Fine-tune for 10 more epochs\n",
    "# total_epochs_final = EPOCHS + total_epochs  # Add to previous epochs\n",
    "\n",
    "history_fine_final = loaded_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "599/599 [==============================] - 192s 321ms/step - loss: 0.2813 - accuracy: 0.9073 - val_loss: 0.5235 - val_accuracy: 0.8428 - lr: 1.0000e-06\n",
      "Epoch 7/10\n",
      "599/599 [==============================] - 191s 318ms/step - loss: 0.2363 - accuracy: 0.9244 - val_loss: 0.4941 - val_accuracy: 0.8505 - lr: 1.0000e-06\n",
      "Epoch 8/10\n",
      "599/599 [==============================] - 192s 320ms/step - loss: 0.1995 - accuracy: 0.9365 - val_loss: 0.4723 - val_accuracy: 0.8562 - lr: 1.0000e-06\n",
      "Epoch 9/10\n",
      "599/599 [==============================] - 219s 366ms/step - loss: 0.1725 - accuracy: 0.9468 - val_loss: 0.4543 - val_accuracy: 0.8623 - lr: 1.0000e-06\n",
      "Epoch 10/10\n",
      "599/599 [==============================] - 192s 320ms/step - loss: 0.1482 - accuracy: 0.9550 - val_loss: 0.4395 - val_accuracy: 0.8660 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history_fine_final = loaded_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs+5,\n",
    "    initial_epoch=5,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "599/599 [==============================] - 187s 311ms/step - loss: 0.1276 - accuracy: 0.9618 - val_loss: 0.4286 - val_accuracy: 0.8731 - lr: 1.0000e-06\n",
      "Epoch 12/15\n",
      "599/599 [==============================] - 189s 316ms/step - loss: 0.1096 - accuracy: 0.9697 - val_loss: 0.4183 - val_accuracy: 0.8757 - lr: 1.0000e-06\n",
      "Epoch 13/15\n",
      "599/599 [==============================] - 192s 320ms/step - loss: 0.0946 - accuracy: 0.9736 - val_loss: 0.4109 - val_accuracy: 0.8808 - lr: 1.0000e-06\n",
      "Epoch 14/15\n",
      "599/599 [==============================] - 190s 318ms/step - loss: 0.0806 - accuracy: 0.9792 - val_loss: 0.4045 - val_accuracy: 0.8808 - lr: 1.0000e-06\n",
      "Epoch 15/15\n",
      "599/599 [==============================] - 189s 316ms/step - loss: 0.0702 - accuracy: 0.9834 - val_loss: 0.3975 - val_accuracy: 0.8834 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model.layers:\n",
    "    if layer.name == \"dense\":\n",
    "        layer.kernel_regularizer = tf.keras.regularizers.l2(1e-3)\n",
    "\n",
    "history_fine_final = loaded_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs+5+5,\n",
    "    initial_epoch=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "599/599 [==============================] - 188s 312ms/step - loss: 0.0599 - accuracy: 0.9862 - val_loss: 0.3934 - val_accuracy: 0.8855 - lr: 1.0000e-06\n",
      "Epoch 17/20\n",
      "599/599 [==============================] - 186s 310ms/step - loss: 0.0514 - accuracy: 0.9900 - val_loss: 0.3879 - val_accuracy: 0.8886 - lr: 1.0000e-06\n",
      "Epoch 18/20\n",
      "599/599 [==============================] - 186s 311ms/step - loss: 0.0446 - accuracy: 0.9920 - val_loss: 0.3848 - val_accuracy: 0.8884 - lr: 1.0000e-06\n",
      "Epoch 19/20\n",
      "599/599 [==============================] - 301s 502ms/step - loss: 0.0382 - accuracy: 0.9942 - val_loss: 0.3803 - val_accuracy: 0.8902 - lr: 1.0000e-06\n",
      "Epoch 20/20\n",
      "599/599 [==============================] - 187s 312ms/step - loss: 0.0332 - accuracy: 0.9954 - val_loss: 0.3792 - val_accuracy: 0.8910 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model.layers:\n",
    "    if layer.name == \"dense\":\n",
    "        layer.kernel_regularizer = tf.keras.regularizers.l2(1e-1)\n",
    "\n",
    "history_fine_final = loaded_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs+5+5+5,\n",
    "    initial_epoch=15,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n",
      "599/599 [==============================] - 187s 311ms/step - loss: 0.0290 - accuracy: 0.9963 - val_loss: 0.3780 - val_accuracy: 0.8921 - lr: 1.0000e-06\n",
      "Epoch 22/25\n",
      "599/599 [==============================] - 211s 351ms/step - loss: 0.0248 - accuracy: 0.9978 - val_loss: 0.3739 - val_accuracy: 0.8940 - lr: 1.0000e-06\n",
      "Epoch 23/25\n",
      "599/599 [==============================] - 187s 312ms/step - loss: 0.0213 - accuracy: 0.9986 - val_loss: 0.3723 - val_accuracy: 0.8961 - lr: 1.0000e-06\n",
      "Epoch 24/25\n",
      "599/599 [==============================] - 193s 323ms/step - loss: 0.0188 - accuracy: 0.9989 - val_loss: 0.3728 - val_accuracy: 0.8964 - lr: 1.0000e-06\n",
      "Epoch 25/25\n",
      "599/599 [==============================] - 187s 312ms/step - loss: 0.0162 - accuracy: 0.9995 - val_loss: 0.3729 - val_accuracy: 0.8973 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model.layers:\n",
    "    if hasattr(layer, \"kernel_regularizer\"):\n",
    "        layer.kernel_regularizer = tf.keras.regularizers.l2(1)\n",
    "\n",
    "history_fine_final = loaded_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs+5+5+5+5,\n",
    "    initial_epoch=20,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "599/599 [==============================] - 196s 326ms/step - loss: 0.0138 - accuracy: 0.9996 - val_loss: 0.3729 - val_accuracy: 0.8987 - lr: 2.0000e-07\n",
      "Epoch 27/30\n",
      "599/599 [==============================] - 187s 312ms/step - loss: 0.0135 - accuracy: 0.9995 - val_loss: 0.3727 - val_accuracy: 0.8982 - lr: 2.0000e-07\n",
      "Epoch 28/30\n",
      "599/599 [==============================] - 186s 311ms/step - loss: 0.0125 - accuracy: 0.9997 - val_loss: 0.3724 - val_accuracy: 0.8999 - lr: 2.0000e-07\n",
      "Epoch 29/30\n",
      "599/599 [==============================] - 186s 311ms/step - loss: 0.0124 - accuracy: 0.9997 - val_loss: 0.3719 - val_accuracy: 0.8999 - lr: 2.0000e-07\n",
      "Epoch 30/30\n",
      "599/599 [==============================] - 186s 311ms/step - loss: 0.0121 - accuracy: 0.9998 - val_loss: 0.3716 - val_accuracy: 0.8999 - lr: 2.0000e-07\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model.layers:\n",
    "    if hasattr(layer, \"kernel_regularizer\"):\n",
    "        layer.kernel_regularizer = tf.keras.regularizers.l2(2)\n",
    "\n",
    "history_fine_final = loaded_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs+5+5+5+5+5,\n",
    "    initial_epoch=25,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/35\n",
      "599/599 [==============================] - 192s 319ms/step - loss: 0.0118 - accuracy: 0.9998 - val_loss: 0.3711 - val_accuracy: 0.8996 - lr: 2.0000e-07\n",
      "Epoch 32/35\n",
      "599/599 [==============================] - 188s 314ms/step - loss: 0.0110 - accuracy: 0.9998 - val_loss: 0.3710 - val_accuracy: 0.9004 - lr: 2.0000e-07\n",
      "Epoch 33/35\n",
      "599/599 [==============================] - 189s 316ms/step - loss: 0.0108 - accuracy: 0.9997 - val_loss: 0.3715 - val_accuracy: 0.9008 - lr: 2.0000e-07\n",
      "Epoch 34/35\n",
      "599/599 [==============================] - 189s 315ms/step - loss: 0.0104 - accuracy: 0.9997 - val_loss: 0.3709 - val_accuracy: 0.9008 - lr: 2.0000e-07\n",
      "Epoch 35/35\n",
      "599/599 [==============================] - 186s 311ms/step - loss: 0.0100 - accuracy: 0.9997 - val_loss: 0.3707 - val_accuracy: 0.9018 - lr: 2.0000e-07\n"
     ]
    }
   ],
   "source": [
    "history_fine_final = loaded_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs+5+5+5+5+5+5,\n",
    "    initial_epoch=30,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "loaded_model.save('arabic_letter_classifier_100_90')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
