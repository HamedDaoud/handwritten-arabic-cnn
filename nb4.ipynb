{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": /physical_device:CPU:0\n",
      ": /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(\": {}\".format(device.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Found 42559 files belonging to 65 classes.\n",
      "Using 38304 files for training.\n",
      "Found 42559 files belonging to 65 classes.\n",
      "Using 4255 files for validation.\n",
      "Found 10640 files belonging to 1 classes.\n",
      "Class names: ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warnings and logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (224, 224)  # Directly using ResNet50 input size\n",
    "BATCH_SIZE = 64\n",
    "TRAINING_DATA_PATH = \"Final_Arabic_Alpha_dataset/train\"\n",
    "TEST_DATA_PATH = \"Final_Arabic_Alpha_dataset/test\"\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAINING_DATA_PATH,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAINING_DATA_PATH,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DATA_PATH,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    label_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model(\"arabic_letter_classifier_95_87\")\n",
    "\n",
    "old_weights = loaded_model.layers[-1].get_weights()\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599/599 [==============================] - 128s 186ms/step - loss: 0.1767 - accuracy: 0.9523\n",
      "67/67 [==============================] - 12s 177ms/step - loss: 0.4037 - accuracy: 0.8717\n",
      "Training loss: 0.17665907740592957, Training Accuracy: 0.9522504210472107\n",
      "Val loss: 0.40373876690864563, Val Accuracy: 0.8716803789138794\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(train_ds)\n",
    "val_loss, val_accuracy = loaded_model.evaluate(val_ds)\n",
    "\n",
    "print(f\"Training loss: {loss}, Training Accuracy: {accuracy}\")\n",
    "print(f\"Val loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "\n",
    "# Identify the correct last dense layer before the output\n",
    "x = loaded_model.layers[-2].output  # Target the last Dense layer before softmax\n",
    "x = Dropout(0.2, name=\"new_dropout\")(x)  # Add Dropout (rename it)\n",
    "x = Dense(len(class_names), activation='softmax', name=\"new_output\")(x)  # Rename new Dense layer\n",
    "\n",
    "# Create new model (Keeps trained weights)\n",
    "new_model = Model(inputs=loaded_model.input, outputs=x)\n",
    "\n",
    "# Set the pre-trained weights back\n",
    "new_model.layers[-1].set_weights(old_weights)  # Restore softmax layer weights\n",
    "\n",
    "# Recompile and continue training\n",
    "new_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2: False\n",
      "tf.__operators__.getitem: False\n",
      "tf.nn.bias_add: False\n",
      "resnet50: True\n",
      "global_average_pooling2d: False\n",
      "dense: True\n",
      "new_dropout: True\n",
      "new_output: True\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 19,994,177\n",
      "Non-trainable params: 4,134,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model.layers:\n",
    "    if layer.name == 'dense':\n",
    "        layer.traiable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "base_model = new_model.get_layer('resnet50')\n",
    "\n",
    "# Unfreeze some layers of the base model\n",
    "fine_tune_at = 100  # Unfreeze from this layer onwards\n",
    "\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "for layer in new_model.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")\n",
    "print()\n",
    "\n",
    "new_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "599/599 [==============================] - 229s 330ms/step - loss: 0.8358 - accuracy: 0.7767 - val_loss: 0.3944 - val_accuracy: 0.8743 - lr: 1.0000e-05\n",
      "Epoch 2/5\n",
      "599/599 [==============================] - 183s 304ms/step - loss: 0.2922 - accuracy: 0.9036 - val_loss: 0.3146 - val_accuracy: 0.9055 - lr: 1.0000e-05\n",
      "Epoch 3/5\n",
      "599/599 [==============================] - 184s 306ms/step - loss: 0.1807 - accuracy: 0.9385 - val_loss: 0.2890 - val_accuracy: 0.9109 - lr: 1.0000e-05\n",
      "Epoch 4/5\n",
      "599/599 [==============================] - 184s 307ms/step - loss: 0.1216 - accuracy: 0.9579 - val_loss: 0.2719 - val_accuracy: 0.9166 - lr: 1.0000e-05\n",
      "Epoch 5/5\n",
      "599/599 [==============================] - 184s 307ms/step - loss: 0.0837 - accuracy: 0.9722 - val_loss: 0.2660 - val_accuracy: 0.9234 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=1e-8\n",
    "    )\n",
    "]\n",
    "\n",
    "history = new_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,  # Continue training\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "new_model.save('arabic_letter_classifier_97_92')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "\n",
    "\n",
    "# Load the model\n",
    "loaded_model2 = tf.keras.models.load_model(\"arabic_letter_classifier_95_87\")\n",
    "\n",
    "old_weights2 = loaded_model2.layers[-1].get_weights()\n",
    "\n",
    "\n",
    "\n",
    "x = loaded_model2.layers[-2].output  # Target the last Dense layer before softmax\n",
    "x = Dropout(0.3, name=\"new_dropout\")(x)  # Add Dropout (rename it)\n",
    "x = Dense(len(class_names), activation='softmax', name=\"new_output\")(x)  # Rename new Dense layer\n",
    "\n",
    "# Create new model (Keeps trained weights)\n",
    "new_model2 = Model(inputs=loaded_model2.input, outputs=x)\n",
    "\n",
    "# Set the pre-trained weights back\n",
    "new_model2.layers[-1].set_weights(old_weights2)  # Restore softmax layer weights\n",
    "\n",
    "# Recompile and continue training\n",
    "new_model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2: False\n",
      "tf.__operators__.getitem: False\n",
      "tf.nn.bias_add: False\n",
      "resnet50: True\n",
      "global_average_pooling2d: False\n",
      "dense: True\n",
      "new_dropout: True\n",
      "new_output: True\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 19,994,177\n",
      "Non-trainable params: 4,134,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model2.layers:\n",
    "    if layer.name == 'dense':\n",
    "        layer.traiable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "base_model2 = new_model2.get_layer('resnet50')\n",
    "\n",
    "# Unfreeze some layers of the base model\n",
    "fine_tune_at = 100  # Unfreeze from this layer onwards\n",
    "\n",
    "base_model2.trainable = True\n",
    "for layer in base_model2.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "for layer in new_model2.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")\n",
    "print()\n",
    "\n",
    "new_model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "599/599 [==============================] - 223s 339ms/step - loss: 1.0032 - accuracy: 0.7397 - val_loss: 0.3891 - val_accuracy: 0.8799 - lr: 1.0000e-05\n",
      "Epoch 2/5\n",
      "599/599 [==============================] - 193s 322ms/step - loss: 0.3707 - accuracy: 0.8782 - val_loss: 0.3047 - val_accuracy: 0.9034 - lr: 1.0000e-05\n",
      "Epoch 3/5\n",
      "599/599 [==============================] - 188s 314ms/step - loss: 0.2413 - accuracy: 0.9199 - val_loss: 0.2764 - val_accuracy: 0.9159 - lr: 1.0000e-05\n",
      "Epoch 4/5\n",
      "599/599 [==============================] - 186s 311ms/step - loss: 0.1711 - accuracy: 0.9404 - val_loss: 0.2551 - val_accuracy: 0.9196 - lr: 1.0000e-05\n",
      "Epoch 5/5\n",
      "599/599 [==============================] - 187s 311ms/step - loss: 0.1235 - accuracy: 0.9565 - val_loss: 0.2497 - val_accuracy: 0.9246 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=1e-8\n",
    "    )\n",
    "]\n",
    "\n",
    "history = new_model2.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "new_model2.save('arabic_letter_classifier_95_92')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "\n",
    "\n",
    "# Load the model\n",
    "loaded_model3 = tf.keras.models.load_model(\"arabic_letter_classifier_95_87\")\n",
    "\n",
    "old_weights3 = loaded_model3.layers[-1].get_weights()\n",
    "\n",
    "\n",
    "\n",
    "x = loaded_model3.layers[-2].output  # Target the last Dense layer before softmax\n",
    "x = Dropout(0.5, name=\"new_dropout\")(x)  # Add Dropout (rename it)\n",
    "x = Dense(len(class_names), activation='softmax', name=\"new_output\")(x)  # Rename new Dense layer\n",
    "\n",
    "# Create new model (Keeps trained weights)\n",
    "new_model3 = Model(inputs=loaded_model3.input, outputs=x)\n",
    "\n",
    "# Set the pre-trained weights back\n",
    "new_model3.layers[-1].set_weights(old_weights3)  # Restore softmax layer weights\n",
    "\n",
    "# Recompile and continue training\n",
    "new_model3.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2: False\n",
      "tf.__operators__.getitem: False\n",
      "tf.nn.bias_add: False\n",
      "resnet50: True\n",
      "global_average_pooling2d: False\n",
      "dense: True\n",
      "new_dropout: True\n",
      "new_output: True\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 19,994,177\n",
      "Non-trainable params: 4,134,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model3.layers:\n",
    "    if layer.name == 'dense':\n",
    "        layer.traiable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "base_model3 = new_model3.get_layer('resnet50')\n",
    "\n",
    "# Unfreeze some layers of the base model\n",
    "fine_tune_at = 100  # Unfreeze from this layer onwards\n",
    "\n",
    "base_model3.trainable = True\n",
    "for layer in base_model3.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "for layer in new_model3.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")\n",
    "print()\n",
    "\n",
    "new_model3.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "599/599 [==============================] - 182s 300ms/step - loss: 1.5437 - accuracy: 0.6420 - val_loss: 0.4007 - val_accuracy: 0.8731 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "599/599 [==============================] - 327s 547ms/step - loss: 0.6134 - accuracy: 0.8035 - val_loss: 0.3018 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "599/599 [==============================] - 179s 298ms/step - loss: 0.4243 - accuracy: 0.8593 - val_loss: 0.2644 - val_accuracy: 0.9152 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "599/599 [==============================] - 190s 317ms/step - loss: 0.3166 - accuracy: 0.8936 - val_loss: 0.2340 - val_accuracy: 0.9276 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "599/599 [==============================] - 179s 298ms/step - loss: 0.2446 - accuracy: 0.9173 - val_loss: 0.2237 - val_accuracy: 0.9293 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "599/599 [==============================] - 179s 298ms/step - loss: 0.1949 - accuracy: 0.9339 - val_loss: 0.2161 - val_accuracy: 0.9354 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "599/599 [==============================] - 179s 298ms/step - loss: 0.1470 - accuracy: 0.9493 - val_loss: 0.2171 - val_accuracy: 0.9389 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "599/599 [==============================] - 189s 316ms/step - loss: 0.1189 - accuracy: 0.9578 - val_loss: 0.2141 - val_accuracy: 0.9389 - lr: 1.0000e-05\n",
      "Epoch 9/10\n",
      "599/599 [==============================] - 179s 299ms/step - loss: 0.0972 - accuracy: 0.9674 - val_loss: 0.2150 - val_accuracy: 0.9382 - lr: 1.0000e-05\n",
      "Epoch 10/10\n",
      "599/599 [==============================] - 179s 299ms/step - loss: 0.0776 - accuracy: 0.9734 - val_loss: 0.2212 - val_accuracy: 0.9403 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=1e-8\n",
    "    )\n",
    "]\n",
    "\n",
    "history = new_model3.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "new_model3.save('arabic_letter_classifier_97_94')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 541,249\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "\n",
    "\n",
    "# Load the model\n",
    "loaded_model4 = tf.keras.models.load_model(\"arabic_letter_classifier_95_87\")\n",
    "\n",
    "old_weights4 = loaded_model4.layers[-1].get_weights()\n",
    "\n",
    "\n",
    "\n",
    "x = loaded_model4.layers[-2].output  # Target the last Dense layer before softmax\n",
    "x = Dropout(0.7, name=\"new_dropout\")(x)  # Add Dropout (rename it)\n",
    "x = Dense(len(class_names), activation='softmax', name=\"new_output\")(x)  # Rename new Dense layer\n",
    "\n",
    "# Create new model (Keeps trained weights)\n",
    "new_model4 = Model(inputs=loaded_model4.input, outputs=x)\n",
    "\n",
    "# Set the pre-trained weights back\n",
    "new_model4.layers[-1].set_weights(old_weights4)  # Restore softmax layer weights\n",
    "\n",
    "# Recompile and continue training\n",
    "new_model4.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2: False\n",
      "tf.__operators__.getitem: False\n",
      "tf.nn.bias_add: False\n",
      "resnet50: True\n",
      "global_average_pooling2d: False\n",
      "dense: True\n",
      "new_dropout: True\n",
      "new_output: True\n",
      "\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " new_dropout (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " new_output (Dense)          (None, 65)                16705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,128,961\n",
      "Trainable params: 19,994,177\n",
      "Non-trainable params: 4,134,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model4.layers:\n",
    "    if layer.name == 'dense':\n",
    "        layer.traiable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "base_model4 = new_model4.get_layer('resnet50')\n",
    "\n",
    "# Unfreeze some layers of the base model\n",
    "fine_tune_at = 100  # Unfreeze from this layer onwards\n",
    "\n",
    "base_model4.trainable = True\n",
    "for layer in base_model4.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "for layer in new_model4.layers:\n",
    "    print(f\"{layer.name}: {layer.trainable}\")\n",
    "print()\n",
    "\n",
    "new_model4.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "new_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "599/599 [==============================] - 183s 301ms/step - loss: 2.6921 - accuracy: 0.4703 - val_loss: 0.4580 - val_accuracy: 0.8620 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "599/599 [==============================] - 176s 293ms/step - loss: 1.1544 - accuracy: 0.6507 - val_loss: 0.3540 - val_accuracy: 0.8971 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "599/599 [==============================] - 176s 294ms/step - loss: 0.8434 - accuracy: 0.7356 - val_loss: 0.2864 - val_accuracy: 0.9166 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "599/599 [==============================] - 176s 294ms/step - loss: 0.6663 - accuracy: 0.7853 - val_loss: 0.2472 - val_accuracy: 0.9241 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "599/599 [==============================] - 176s 294ms/step - loss: 0.5189 - accuracy: 0.8343 - val_loss: 0.2255 - val_accuracy: 0.9316 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "599/599 [==============================] - 191s 319ms/step - loss: 0.4238 - accuracy: 0.8637 - val_loss: 0.2126 - val_accuracy: 0.9349 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "599/599 [==============================] - 176s 293ms/step - loss: 0.3482 - accuracy: 0.8866 - val_loss: 0.2056 - val_accuracy: 0.9370 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "599/599 [==============================] - 177s 295ms/step - loss: 0.2840 - accuracy: 0.9083 - val_loss: 0.1980 - val_accuracy: 0.9373 - lr: 1.0000e-05\n",
      "Epoch 9/10\n",
      "599/599 [==============================] - 189s 315ms/step - loss: 0.2362 - accuracy: 0.9236 - val_loss: 0.1903 - val_accuracy: 0.9443 - lr: 1.0000e-05\n",
      "Epoch 10/10\n",
      "599/599 [==============================] - 177s 294ms/step - loss: 0.1982 - accuracy: 0.9344 - val_loss: 0.1943 - val_accuracy: 0.9452 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = new_model4.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "599/599 [==============================] - 177s 294ms/step - loss: 0.1663 - accuracy: 0.9454 - val_loss: 0.1930 - val_accuracy: 0.9450 - lr: 1.0000e-07\n",
      "Epoch 12/15\n",
      "599/599 [==============================] - 176s 294ms/step - loss: 0.1625 - accuracy: 0.9462 - val_loss: 0.1924 - val_accuracy: 0.9455 - lr: 1.0000e-07\n",
      "Epoch 13/15\n",
      "599/599 [==============================] - 176s 294ms/step - loss: 0.1564 - accuracy: 0.9484 - val_loss: 0.1918 - val_accuracy: 0.9457 - lr: 1.0000e-07\n",
      "Epoch 14/15\n",
      "599/599 [==============================] - 177s 295ms/step - loss: 0.1585 - accuracy: 0.9473 - val_loss: 0.1916 - val_accuracy: 0.9455 - lr: 1.0000e-07\n",
      "Epoch 15/15\n",
      "599/599 [==============================] - 176s 294ms/step - loss: 0.1569 - accuracy: 0.9485 - val_loss: 0.1914 - val_accuracy: 0.9452 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "new_model4.optimizer.learning_rate.assign(1e-7)\n",
    "\n",
    "history = new_model4.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    initial_epoch=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "new_model4.save('arabic_letter_classifier_95_95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "599/599 [==============================] - 186s 308ms/step - loss: 0.1539 - accuracy: 0.9481 - val_loss: 0.1913 - val_accuracy: 0.9450 - lr: 1.0000e-09\n",
      "Epoch 17/20\n",
      "599/599 [==============================] - 179s 298ms/step - loss: 0.1550 - accuracy: 0.9496 - val_loss: 0.1913 - val_accuracy: 0.9452 - lr: 1.0000e-09\n",
      "Epoch 18/20\n",
      "599/599 [==============================] - 178s 297ms/step - loss: 0.1537 - accuracy: 0.9511 - val_loss: 0.1913 - val_accuracy: 0.9452 - lr: 1.0000e-09\n",
      "Epoch 19/20\n",
      "599/599 [==============================] - 177s 295ms/step - loss: 0.1521 - accuracy: 0.9486 - val_loss: 0.1912 - val_accuracy: 0.9452 - lr: 1.0000e-09\n",
      "Epoch 20/20\n",
      "599/599 [==============================] - 181s 301ms/step - loss: 0.1549 - accuracy: 0.9470 - val_loss: 0.1912 - val_accuracy: 0.9452 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "new_model4.optimizer.learning_rate.assign(1e-9)\n",
    "\n",
    "history = new_model4.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    initial_epoch=15,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
